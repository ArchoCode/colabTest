{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simpleClassificationModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lmfCuWd_Nj7OON2UtthFmRqDwGzwii_4",
      "authorship_tag": "ABX9TyNZR45XScTCffL5XDP7vYDy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArchoCode/colabTest/blob/main/simpleClassificationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vyqrKzSqJ1b"
      },
      "source": [
        "install emojis package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikNnEy4XqPhB"
      },
      "source": [
        "!pip install -U -q emoji"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z8bkGqX5LKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021d9e14-8f9a-4085-b3d0-3088c65d24a6"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sklearn.metrics as sm\r\n",
        "%matplotlib inline\r\n",
        "import re\r\n",
        "import emoji\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from textblob import TextBlob\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m0KeGyiOF2e"
      },
      "source": [
        "data_set= pd.read_csv('/content/tweets.csv')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FDpZjS-TOppE",
        "outputId": "30f0647f-0de1-4afc-efc8-6720e9fa9a6b"
      },
      "source": [
        "data_set.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>නැති බැරි කම් අග හිග කම් මැද ජීවත් වෙනවට වඩා හ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>ඔබ සැමට සුභ දවසක් වේවා!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>හැමදේම අත හැර ගියා නම් හරි වගේ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>රෑට දිලිසෙන ලුමිනස් පාට තරු ටිකක් කාමරේ ඇලෙව්ව...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>මට මානසික ගැටලුවක් තියෙනවා. කතාකරන්න පුලුවන් ක...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                            Comment  label\n",
              "0  1  නැති බැරි කම් අග හිග කම් මැද ජීවත් වෙනවට වඩා හ...      1\n",
              "1  2                            ඔබ සැමට සුභ දවසක් වේවා!      0\n",
              "2  3                    හැමදේම අත හැර ගියා නම් හරි වගේ       1\n",
              "3  4  රෑට දිලිසෙන ලුමිනස් පාට තරු ටිකක් කාමරේ ඇලෙව්ව...      0\n",
              "4  5  මට මානසික ගැටලුවක් තියෙනවා. කතාකරන්න පුලුවන් ක...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0l3Dubyb9pI"
      },
      "source": [
        "Text cleaning of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "p2I54igC3MTs",
        "outputId": "e9e985ef-ad0a-42e7-fac1-00c666c281c0"
      },
      "source": [
        "def clean_text(df, text_field,new_text_field):\r\n",
        "    df[new_text_field]=df[text_field]\r\n",
        "    # remove numbers\r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\r\n",
        "    #remove url\r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", elem))\r\n",
        "    #remove HTML tags\r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r\"<.*?>\", \"\", elem))\r\n",
        "    #remove emojis \r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: emoji.get_emoji_regexp().sub(r\" \", elem))\r\n",
        "    #remove re-tweets status \r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r'^RT @\\w*: ', ' ', elem))\r\n",
        "    #remove mentions \r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r'@\\w*', ' ', elem))\r\n",
        "    #remove special characters \r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r'[!@#&*$.?,]', ' ', elem))\r\n",
        "    #remove \\n\r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(r'\\n', ' ', elem))\r\n",
        "    #remove ''\r\n",
        "    df[new_text_field] = df[new_text_field].apply(lambda elem: re.sub(\"'\", '', elem))\r\n",
        "    \r\n",
        "    return df\r\n",
        "\r\n",
        "#tokenizing\r\n",
        "def tokenize(df,text_field,new_text_field):\r\n",
        "  df[new_text_field]=df[text_field]\r\n",
        "  df[new_text_field]=df[new_text_field].apply(word_tokenize)\r\n",
        "  return df\r\n",
        "\r\n",
        "clean_data = clean_text(data_set,'Comment','text_clean')\r\n",
        "tokenize_data=tokenize(data_set,'text_clean','tokenized_text')\r\n",
        "clean_data.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Comment</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>නැති බැරි කම් අග හිග කම් මැද ජීවත් වෙනවට වඩා හ...</td>\n",
              "      <td>1</td>\n",
              "      <td>නැති බැරි කම් අග හිග කම් මැද ජීවත් වෙනවට වඩා හ...</td>\n",
              "      <td>[නැති, බැරි, කම්, අග, හිග, කම්, මැද, ජීවත්, වෙ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>ඔබ සැමට සුභ දවසක් වේවා!</td>\n",
              "      <td>0</td>\n",
              "      <td>ඔබ සැමට සුභ දවසක් වේවා</td>\n",
              "      <td>[ඔබ, සැමට, සුභ, දවසක්, වේවා]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>හැමදේම අත හැර ගියා නම් හරි වගේ</td>\n",
              "      <td>1</td>\n",
              "      <td>හැමදේම අත හැර ගියා නම් හරි වගේ</td>\n",
              "      <td>[හැමදේම, අත, හැර, ගියා, නම්, හරි, වගේ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>රෑට දිලිසෙන ලුමිනස් පාට තරු ටිකක් කාමරේ ඇලෙව්ව...</td>\n",
              "      <td>0</td>\n",
              "      <td>රෑට දිලිසෙන ලුමිනස් පාට තරු ටිකක් කාමරේ ඇලෙව්ව...</td>\n",
              "      <td>[රෑට, දිලිසෙන, ලුමිනස්, පාට, තරු, ටිකක්, කාමරේ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>මට මානසික ගැටලුවක් තියෙනවා. කතාකරන්න පුලුවන් ක...</td>\n",
              "      <td>1</td>\n",
              "      <td>මට මානසික ගැටලුවක් තියෙනවා  කතාකරන්න පුලුවන් ක...</td>\n",
              "      <td>[මට, මානසික, ගැටලුවක්, තියෙනවා, කතාකරන්න, පුලු...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  ...                                     tokenized_text\n",
              "0  1  ...  [නැති, බැරි, කම්, අග, හිග, කම්, මැද, ජීවත්, වෙ...\n",
              "1  2  ...                       [ඔබ, සැමට, සුභ, දවසක්, වේවා]\n",
              "2  3  ...             [හැමදේම, අත, හැර, ගියා, නම්, හරි, වගේ]\n",
              "3  4  ...  [රෑට, දිලිසෙන, ලුමිනස්, පාට, තරු, ටිකක්, කාමරේ...\n",
              "4  5  ...  [මට, මානසික, ගැටලුවක්, තියෙනවා, කතාකරන්න, පුලු...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CPyqMQf1vBk"
      },
      "source": [
        "Test & Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D37Dr8RN1xar"
      },
      "source": [
        "# extract the labels from the train data\r\n",
        "y = data_set.label.values\r\n",
        "\r\n",
        "# use 70% for the training and 30% for the test\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_set.text_clean.values, y, \r\n",
        "                                                    stratify=y, \r\n",
        "                                                    random_state=1, \r\n",
        "                                                    test_size=0.3, shuffle=True)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7t5PWJ52FED"
      },
      "source": [
        "Vectorize tweets using CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79HHU5gwJoyV"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "# vectorize tweets for model building\r\n",
        "vectorizer = CountVectorizer(binary=True)\r\n",
        "\r\n",
        "# learn a vocabulary dictionary of all tokens in the raw documents\r\n",
        "vectorizer.fit(list(x_train) + list(x_test))\r\n",
        "\r\n",
        "# transform documents to document-term matrix\r\n",
        "x_train_vec = vectorizer.transform(x_train)\r\n",
        "x_test_vec = vectorizer.transform(x_test)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnPwlOCK3yM9"
      },
      "source": [
        "Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eS_ggoA30ir"
      },
      "source": [
        "SVM classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfz7SLcnJ1S1"
      },
      "source": [
        "from sklearn import svm\r\n",
        "# classify using support vector classifier\r\n",
        "svm = svm.SVC(kernel = 'linear', probability=True)\r\n",
        "\r\n",
        "# fit the SVC model based on the given training data\r\n",
        "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\r\n",
        "\r\n",
        "# perform classification and prediction on samples in x_test\r\n",
        "y_pred_svm = svm.predict(x_test_vec)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rTnLPq-LEbJ"
      },
      "source": [
        "Accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bbBcCMQJ6Ys",
        "outputId": "0fca2456-a224-452f-c83f-9c4ddd1f2350"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for SVC is:  65.75342465753424 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EsgpR5PXLi"
      },
      "source": [
        "def classify_tweet(arr):\r\n",
        "  return svm.predict(vectorizer.transform(arr))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHmwQY-KPn-k",
        "outputId": "8d0b70ff-6b13-4df0-bfb7-ab7caa12a6a0"
      },
      "source": [
        "msg=[\"මම සතුටින් ඉන්නෙ\"]\r\n",
        "for index_instance,instance in enumerate(classify_tweet(msg)):\r\n",
        "  print(msg[index_instance], ' - ',instance)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "මම සතුටින් ඉන්නෙ  -  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXKg8JVnTv7O"
      },
      "source": [
        "මම සතුටින් ඉන්නෙ\r\n",
        "මට මානසික ගැටලුවක් තියෙනවා"
      ]
    }
  ]
}